{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# 사이킷런: 머신러닝 package로 가장 파이썬스로운 API를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "# 사이킷런의 많은 샘플 데이터 중 붓꽃 품종 데이터를 가져옴\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터를 train과 test로 분류해주는 라이브러리\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명:  ['setosa' 'versicolor' 'virginica']\n",
      "iris feature명:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# 우선 필요한 데이터를 불러옵니다\n",
    "\n",
    "iris= load_iris()\n",
    "\n",
    "iris_data = iris.data\n",
    "\n",
    "iris_label = iris.target\n",
    "\n",
    "print('iris target값: ', iris_label)\n",
    "print('iris target명: ', iris.target_names)\n",
    "\n",
    "# 이미 정제된 데이터이기에 iris.target_names 등를 뽑아낼 수 있다.\n",
    "print('iris feature명: ', iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data =iris_data, columns = iris.feature_names)\n",
    "# 기존의 ndarray형태였떤 iris_data를 데이터프레임화 합니다.\n",
    "# column은 feature_names로 세팅\n",
    "\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()\n",
    "# 서로 다른 데이터 꽃들이 150개 존재 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names 의 type: <class 'list'>\n",
      " feature_names 의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names 의 type: <class 'numpy.ndarray'>\n",
      " feature_names 의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data 의 type: <class 'numpy.ndarray'>\n",
      " data 의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target 의 type: <class 'numpy.ndarray'>\n",
      " target 의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('\\n feature_names 의 type:',type(iris_data.feature_names))\n",
    "print(' feature_names 의 shape:',len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names 의 type:',type(iris_data.target_names))\n",
    "print(' feature_names 의 shape:',len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data 의 type:',type(iris_data.data))\n",
    "print(' data 의 shape:',iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n target 의 type:',type(iris_data.target))\n",
    "print(' target 의 shape:',iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습/테스트 데이터 셋 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  1.0\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # iris data set 뽑아왔다.\n",
    "dt_clf = DecisionTreeClassifier() # 디시션트리분류메서드 할당\n",
    "\n",
    "train_data = iris.data # iris data에서 레이블이 아닌 부분(iris.data)\n",
    "train_label = iris.target #iris data에서 label부분(iris.target)\n",
    "#즉, data를 활용/추론하여 target이라는 결론을 이끌어낸다.(target:분류된 것)\n",
    "\n",
    "dt_clf.fit(train_data, train_label) # 학습 진행\n",
    "# train,test로 분류하지 않은 상태에서 학습 진행\n",
    "\n",
    "\n",
    "# 학습 데이터 셋으로 예측 수행\n",
    "pred = dt_clf.predict(train_data) \n",
    "#디시션트리분류 메서드의 predict 메서드로 train_data 인수로 받는다, pred에 저장.\n",
    "print('예측 정확도: ', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  train과 test로 분리 없이 학습을 진행하였기에 예측 정확도는 1이 나온다. (=예측을 모두 맞췄다는 뜻일 수도 있지만, 이미 정해져 있는 결과를 그대로 가져왔다는 뜻이기도 하다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state = 121)\n",
    "# X_train, X_test는 학습용 feature 데이터 셋\n",
    "# y_train, y_test는 학습용 레이블 데이터와 테스트용 레이블 데이터\n",
    "\n",
    "dt_clf.fit(X_train, y_train) \n",
    "# DecisionTreeClasifier의 객체 dt_clf로 학습 데이터를 학습(fit)\n",
    "# dt_clf객체는 학습한 데이터의 내용(?)을 기반으로, X_test 데이터를 예측(predict())한다.\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 학습데이터로 학습한 알고리즘을 기반으로 새로운 데이터를 학습할 때, 얼마나 잘 예측했는지 검증\n",
    "print('예측 정확도: {0: .4}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. DecisionTreeClassifier는 어떤 알고리즘이길래??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df['target'] = iris_data.target\n",
    "# iris_df['target']=iris_data.target\n",
    "\n",
    "tr_df= iris_df.iloc[:,:-1]\n",
    "tgt_df = iris_df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(tr_df, tgt_df, test_size = 0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),type(X_test),type(y_train),type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(\"예측 정확도: {0: .4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증\n",
    "\n",
    "## K 폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris() # 데이터 가져오기\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156) # features, label, DecisionTreeClassifer 호출\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체 (KFold 라이브러리에서 kfold객체 선언)\n",
    "kfold = KFold(n_splits=5) \n",
    "\n",
    "# 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])\n",
    "\n",
    "# row가 150개라는 뜻이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold객체의 split( ) 호출하면 \n",
    "# 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  \n",
    "for train_index, test_index  in kfold.split(features):\n",
    "    \n",
    "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    \n",
    "    # 검증용 테스트 데이터 추출\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    #학습 및 예측 \n",
    "    dt_clf.fit(X_train , y_train) \n",
    "    # 이전에는 그냥 train_test_split()으로 나눴는데, 이번엔 KFold로 train과 test분류함\n",
    "    \n",
    "    # fit --> predict\n",
    "    pred = dt_clf.predict(X_test) # 즉 pred는 y_test를 예측한 것\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복 시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 즉, train_test_split()은 학습-검증 데이터 세트로 한번만 나누는 반면, \n",
    "# 교차검증(KFold)는 서로 다른 학습-검증 데이터 세트를 여러개 만들어 \n",
    "# DecisionTreeClassifier로 학습시킨다\n",
    "\n",
    "###  동일한 데이터 세트를 어떻게 나누느냐의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified K폴드\n",
    "\n",
    "- 기존 k 폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()  \n",
    "# valuecounts = 해당 데이터가 몇개나 있는지 분류해주는 메소드\n",
    "\n",
    "# 전체 150개의 데이터가 3개의 분류로 나뉘어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 교차 검증: 1\n",
      "train label 데이터 분포: \n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "test label 데이터 분포: \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차 검증: 2\n",
      "train label 데이터 분포: \n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "test label 데이터 분포: \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차 검증: 3\n",
      "train label 데이터 분포: \n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "test label 데이터 분포: \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 3)\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "# train_test_split() => kfold.split()\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter +=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('\\n## 교차 검증: {0}'.format(n_iter))\n",
    "    print('train label 데이터 분포: \\n',label_train.value_counts())\n",
    "    print('test label 데이터 분포: \\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stratified k폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 교차 검증: 1\n",
      "train label 데이터 분포:\n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "test label 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "---------------------\n",
      "\n",
      "## 교차 검증: 2\n",
      "train label 데이터 분포:\n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "test label 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "---------------------\n",
      "\n",
      "## 교차 검증: 3\n",
      "train label 데이터 분포:\n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "test label 데이터 분포:\n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "#위의 과정과 비교해서 다른 점은, 이 코드는 전체 데이터와 레이블 데이터로 쪼갠다.\n",
    "# 위의 코드가 한 세션당 3개로 쪼개졌다면, 여긴 6개로 쪼개진다.\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('\\n## 교차 검증: {0}'.format(n_iter))\n",
    "    print('train label 데이터 분포:\\n', label_train.value_counts(), '\\n')\n",
    "    print('test label 데이터 분포:\\n', label_test.value_counts())\n",
    "    print('---------------------')\n",
    "\n",
    "# 그래서 이건, 이전에 학습데이터 뭉텅이, 그 안에서 더 쪼개 검증을 하겠단 소리여\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StratifiedKFold, not KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 99, 검증 데이터 크기: 51\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116]\n",
      "\n",
      "#2 교차 검증 정확도 :0.922, 학습 데이터 크기: 99, 검증 데이터 크기: 51\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133]\n",
      "\n",
      "#3 교차 검증 정확도 :0.979, 학습 데이터 크기: 102, 검증 데이터 크기: 48\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  98  99 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 교차 검증별 정확도: [0.98  0.922 0.979]\n",
      "## 평균 검증 정확도: 0.9603333333333334\n"
     ]
    }
   ],
   "source": [
    "skFold = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "# features와 label은 어디서 정의 된 것?\n",
    "for train_index, test_index in skFold.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred),3)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "print(\"\\n ## 교차 검증별 정확도:\", np.round(cv_accuracy, 3))\n",
    "print(\"## 평균 검증 정확도:\", np.mean(cv_accuracy))\n",
    "\n",
    "# 왜 마지막 검증에서 인덱스가 하나 더 추가 됐는지 알겠네. fucking logical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 분류 방식은 DecisionTreeClassifier를 기반으로 한다\n",
    "\n",
    "- train_test_split: 0.9556\n",
    "- KFold: 0.9\n",
    "- StratifiedKFold: 0.96\n",
    "- 결국 StratifiedKFold의 성능이 KFold보다 조금 더 낫다는 걸 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross_val_score()\n",
    "\n",
    "- 이전의 방법들 보다 간단할 뿐더러 성능도 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도:  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score , cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data =load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "# cross_val_score : 교차검증 메소드(디시션트리, 피쳐, 레이블, 정확도와 분류 세개..?)\n",
    "print('교차 검증별 정확도: ',np.round(scores, 4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV는 따로 정리..이해를 못했거든요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state = 121)\n",
    "dtree = DecisionTreeClassifier(random_state = 126)\n",
    "\n",
    "### parameter 들은 dictionary 형태로 설정\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv = 3, refit = True, return_train_score=True)\n",
    "\n",
    "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과는 cv_results_ 라는 딕셔너리로 저장됨. 이를 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
